#!/bin/bash

# Script para probar la conexi√≥n con Ollama y el backend
# Uso: ./scripts/test-ollama.sh

API_URL="http://localhost:3001"
OLLAMA_URL="http://localhost:11434"

echo "üß™ Probando conexi√≥n con ExpertMind Backend..."
echo "================================================"

# Funci√≥n para hacer peticiones con manejo de errores
make_request() {
    local url=$1
    local method=${2:-GET}
    local data=${3:-}
    
    if [ -n "$data" ]; then
        curl -s -X "$method" "$url" \
             -H "Content-Type: application/json" \
             -d "$data" \
             -w "\nHTTP Status: %{http_code}\n"
    else
        curl -s -X "$method" "$url" \
             -w "\nHTTP Status: %{http_code}\n"
    fi
}

echo "1. üè• Health check del backend..."
make_request "$API_URL/health"
echo ""

echo "2. üîå Estado de conexi√≥n con Ollama..."
make_request "$API_URL/ollama/status"
echo ""

echo "3. üìã Modelos disponibles en Ollama..."
make_request "$API_URL/ollama/models"
echo ""

echo "4. üí¨ Prueba de chat con TinyLlama..."
chat_data='{
  "model": "tinyllama",
  "messages": [
    {
      "role": "user",
      "content": "Hola, responde brevemente: ¬øqu√© es Node.js?"
    }
  ],
  "options": {
    "temperature": 0.7
  }
}'

make_request "$API_URL/ollama/chat" "POST" "$chat_data"
echo ""

echo "5. ü§ñ Prueba de generaci√≥n simple..."
generate_data='{
  "model": "tinyllama",
  "prompt": "Escribe una oraci√≥n sobre inteligencia artificial:",
  "options": {
    "temperature": 0.8
  }
}'

make_request "$API_URL/ollama/generate" "POST" "$generate_data"
echo ""

echo "‚úÖ Pruebas completadas!"
echo ""
echo "üîó Enlaces √∫tiles:"
echo "   ‚Ä¢ API Health: $API_URL/health"
echo "   ‚Ä¢ Documentaci√≥n: $API_URL/api"
echo "   ‚Ä¢ Ollama API: $OLLAMA_URL/api/tags"
